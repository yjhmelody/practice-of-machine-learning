'''
1.æ”¶é›†æ•°æ®
2.å‡†å¤‡æ•°æ®ï¼Œç”±äºéœ€è¦è®¡ç®—è·ç¦»ï¼Œå› æ­¤è¦æ±‚æ•°å€¼å‹ï¼Œå¦å¤–ï¼Œç»“æ„åŒ–æ•°æ®æœ€ä½³
å¤„ç†æ•°æ®ä¸­çš„ç¼ºå¤±å€¼å¯é€‰æ–¹æ³•ï¼š
    ä½¿ç”¨å¯ç”¨ç‰¹å¾çš„å‡å€¼æ¥å¡«è¡¥ç¼ºå¤±å€¼
    ä½¿ç”¨ç‰¹æ®Šå€¼æ¥å¡«è¡¥ç¼ºå¤±å€¼ï¼Œå¦‚-1
    å¿½ç•¥æœ‰ç¼ºå¤±å€¼çš„æ ·æœ¬
    ä½¿ç”¨ç›¸ä¼¼æ ·æœ¬çš„å‡å€¼å¡«è¡¥ç¼ºå¤±å€¼
    ä½¿ç”¨å¦å¤–çš„æœºå™¨å­¦ä¹ ç®—æ³•é¢„æµ‹ç¼ºå¤±å€¼

3.åˆ†ææ•°æ®ï¼Œé‡‡ç”¨ä»»æ„æ–¹æ³•
4.è®­ç»ƒç®—æ³•ï¼Œå¤§éƒ¨åˆ†æ—¶é—´ç”¨äºè®­ç»ƒï¼Œç›®çš„æ˜¯ä¸ºæ‰¾åˆ°æœ€ä½³çš„åˆ†ç±»å›å½’ç³»æ•°
5.æµ‹è¯•ç®—æ³•ï¼Œä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œåˆ†ç±»å°†ä¼šå¾ˆå¿«
6.ä½¿ç”¨ç®—æ³•ï¼Œè¾“å…¥ä¸€äº›æ•°æ®å¹¶è½¬æ¢ä¸ºå¯¹åº”çš„ç»“æ„åŒ–æ•°æ®ï¼›
åŸºäºè®­ç»ƒå¥½çš„å›å½’ç³»æ•°å¯ä»¥å¯¹è¿™äº›æ•°æ®è¿›è¡Œç®€å•çš„å›å½’è®¡ç®—ï¼Œå¹¶åˆ¤å®šç±»åˆ«ï¼›
ä¹‹åå°±å¯ä»¥åœ¨è¾“å‡ºçš„ç±»åˆ«ä¸Šåšå…¶ä»–åˆ†æå·¥ä½œ
'''

import numpy as np
import matplotlib.pyplot as plt


def load_dataset(filename):
    data = []
    label = []
    with open(filename) as f:
        for line in f.readlines():
            line = line.strip().split()
            data.append([1, line[0], line[1]])
            label.append(line[2])
    return data, label


def sigmoid(z):
    '''ç±»è·ƒé˜¶å‡½æ•°'''
    return 1 / (1 + np.exp(-z))


def gradient_ascent(X, y, alpha=0.00128, iterations=3000):
    '''æ¢¯åº¦ä¸Šå‡ç®—æ³•'''
    # é¢„å¤„ç†
    X = np.array(X, dtype=np.float64)
    y = np.array(y, dtype=np.float64).transpose()

    X_T = X.T
    # thetaåˆå§‹åŒ–ä¸ºé•¿åº¦ä¸ºç‰¹å¾æ•°çš„åˆ—å‘é‡
    theta = np.ones(X.shape[1])
    # æ ·æœ¬æ•°
    m = X.shape[0]
    for iteration in range(iterations):
        h = sigmoid(np.dot(X, theta))
        loss = y - h
        # theta = theta + alpha * np.dot(X_T, loss) / m
        theta = theta + alpha * np.dot(X_T, loss)

    cost = np.sum(loss ** 2) / (2 * m)
    print('the cost is: ', cost)
    print('the theta is: ', theta)
    return theta


def SGA(X, y, init_alpha=0.01, iterations=300):
    '''éšæœºæ¢¯åº¦ä¸Šå‡ç®—æ³•'''
    # é¢„å¤„ç†
    X = np.array(X, dtype=np.float64)
    y = np.array(y, dtype=np.float64).transpose()

    m, n = X.shape
    theta = np.ones(n)
    # æ¯æ¬¡éšæœºé€‰æ‹©ä¸€ä¸ªæ¥è¿›è¡Œæ¢¯åº¦ä¸Šå‡
    # æ€»è¿­ä»£æ¬¡æ•°æ˜¯ iterations * m
    for iteration in range(iterations):
        for i in range(m):
            # éšè¿­ä»£é€’å‡å­¦ä¹ ç‡
            alpha = 4 / (1 + i + iteration) + init_alpha
            # ä»mä¸ªæ ·æœ¬é‡Œéšæœºé€‰æ‹©ä¸€ä¸ª
            rand_index = int(np.random.uniform(0, m))
            h = sigmoid(np.sum(X[rand_index] * theta))
            loss = y[rand_index] - h
            theta = theta + alpha * np.dot(X[rand_index], loss)

    return theta


def plot_logistic_regression(data, label, weights):
    data = np.array(data)

    n = np.shape(data)[0]
    x1, y1, x2, y2 = [], [], [], []

    for i in range(n):
        # str -> int
        if int(label[i]) == 1:
            x1.append(data[i, 1])
            y1.append(data[i, 2])
        else:
            x2.append(data[i, 1])
            y2.append(data[i, 2])
    plt.scatter(x1, y1, s=20, c='red')
    plt.scatter(x2, y2, s=20, c='green')

    x = np.arange(-3.0, 3.0, 0.1)
    y = (-weights[0] - weights[1] * x) / weights[2]
    plt.plot(x, y)

    plt.xlabel('X1')
    plt.ylabel('X2')
    plt.show()


def classify_vector(X, weights):
    '''æ ¹æ®sigmoidæ¥äºŒåˆ†ç±»'''
    p = sigmoid(np.dot(X, weights))
    if p > 0.5:
        return 1
    else:
        return 0


def colic_test(iterations=500):
    '''ç–æ°”ç—…é¢„æµ‹ç—…é©¬ğŸçš„æ­»äº¡ç‡'''
    file_train = open('horseColicTraining.txt')
    file_test = open('horseColicTest.txt')
    X_train, y_train = [], []

    for line in file_train.readlines():
        line = line.strip().split('\t')
        feature_vector = []
        # ç‰¹å¾æ•°
        for i in range(21):
            feature_vector.append(float(line[i]))
        X_train.append(feature_vector)
        # ç±»åˆ«
        y_train.append(line[21])

    # è®­ç»ƒweights
    train_weights = SGA(np.array(X_train, dtype=np.float64),
                        y_train, iterations=iterations)
    # è¿›è¡Œé¢„æµ‹å¹¶æ±‚é”™è¯¯ç‡
    error_count = 0
    pred_count = 0
    for line in file_test.readlines():
        line = line.strip().split('\t')
        feature_vector = []
        for i in range(21):
            feature_vector.append(float(line[i]))
            # æµ‹è¯•
        if int(classify_vector(np.array(feature_vector, dtype=np.float64), train_weights)) != int(line[21]):
            error_count += 1
        pred_count += 1
    error_rate = float(error_count) / pred_count
    print('the error rate of this test is: %f' % error_rate)
    return error_rate


def multi_test(num_test, iterations):
    error_sum = 0
    for i in range(num_test):
        error_sum += colic_test(iterations)
    print('after %d test with %d iterations, the average error rate is: %f' %
          (num_test, iterations, error_sum / num_test))


if __name__ == '__main__':
    data, label = load_dataset('testSet.txt')
    # weights1 = gradient_ascent(data, label, alpha=0.0128, iterations=30000)
    # print(weights1)
    # weights2 = SGA(data, label, init_alpha=0.01, iterations=30000)
    # print(weights2)
    # plot_logistic_regression(data, label, weights1)
    # plot_logistic_regression(data, label, weights2)

    multi_test(num_test=20, iterations=100)
